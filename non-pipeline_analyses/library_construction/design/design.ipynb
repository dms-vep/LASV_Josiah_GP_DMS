{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for analyzing mammarenavirus GPC sequences and designing a LASV GP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "\n",
    "from plotnine import *\n",
    "from Bio import SeqIO, AlignIO, Phylo\n",
    "\n",
    "from Bio.Align import MultipleSeqAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CBP = ('#999999', '#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7')\n",
    "theme_set(theme_seaborn(style='darkgrid', context='talk', font_scale=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up percent identiity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def percent_ids(s1, s2, id2):\n",
    "    assert len(s1) == len(s2), 'sequences of unequal length'\n",
    "    length = len(s1)\n",
    "    num_gaps = s1.count('-')\n",
    "    num_aas = length - num_gaps\n",
    "    difs_aa = 0\n",
    "    difs_gap1 = 0\n",
    "    difs_gap2 = 0\n",
    "    id_gaps = 0\n",
    "    for i in range(length):\n",
    "        if s1[i] == '-':\n",
    "            if s2[i] != '-':\n",
    "                difs_gap1 += 1\n",
    "            else:\n",
    "                id_gaps += 1\n",
    "                \n",
    "        elif s2[i] == '-':\n",
    "            difs_gap2 += 1\n",
    "            \n",
    "        elif s1[i] != s2[i]:\n",
    "            difs_aa += 1\n",
    "        \n",
    "        else:\n",
    "            assert s1[i] == s2[i], f\"ID determination error: s1 = {s1[i]}, s2={s2[i]}\"\n",
    "   \n",
    "    pid_dict = {'seq_id': [id2],\n",
    "                'pid_aa': [(num_aas-difs_aa)/num_aas], \n",
    "                'pid_gaps': [(id_gaps)/num_gaps],\n",
    "                'p_aa1_gap2': [(difs_gap2)/num_aas],\n",
    "                'p_gap1_aa2': [(difs_gap1)/num_gaps]}\n",
    "    \n",
    "    return(pd.DataFrame(pid_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "percent_ids('-G-AT', '-CG-T', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up downloaded sequences\n",
    "\n",
    "First look at all sequences and checkout length distribution.\n",
    "\n",
    "I started with the \"Mammarenavirus GPC\" search on GenBank, but also did a \"Mammarenavirus glycoprotein\" GenBank search and a couple searches of the [VIPR database](https://www.viprbrc.org/brc/search_landing.spg?decorator=arena). I will look at length distributions for all of those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def df_len_plot(file):\n",
    "    with open(file) as fasta_file:\n",
    "        ids = []\n",
    "        seqs = []\n",
    "        lengths = []\n",
    "        descriptions = []\n",
    "        for seq_record in SeqIO.parse(fasta_file, 'fasta'):\n",
    "            ids.append(seq_record.id)\n",
    "            lengths.append(len(seq_record.seq))\n",
    "            seqs.append(str(seq_record.seq))\n",
    "            descriptions.append(seq_record.description)\n",
    "\n",
    "    seqs_df = pd.DataFrame(dict(ID=ids, Length=lengths, Description=descriptions, Seq=seqs))\n",
    "    \n",
    "    print(f\"Sequence count: {len(seqs_df)}\")\n",
    "    display(seqs_df.head())\n",
    "    \n",
    "    lengths_plot = (ggplot(seqs_df, aes(x='Length')) +\n",
    "                    geom_histogram(binwidth=10) \n",
    "                   )\n",
    "\n",
    "    _ = lengths_plot.draw()\n",
    "    \n",
    "    return(seqs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gb_mammarenavirus_gpc = df_len_plot('./seq_downloads/mammarenavirus_gpcs_all.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gb_mammarenavirus_glycoprotein = df_len_plot('./seq_downloads/mammarenavirus_glycoprotein_all.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vipr_mammarenavirus = df_len_plot('./seq_downloads/mammarenavirus_gp_viprbrc.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vipr_arenaviridae = df_len_plot('./seq_downloads/arenaviridae_gp_viprbrc.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most sequences from the GenBank \"GPC\" search look like full-length GPC, right around 500 amino acids in length. There are clearly some mislablled sequennces in the \"glycoprotein\" search, but even still there are more full-length sequences there. \n",
    "\n",
    "However, most of the VIPR sequences seem to be partial sequences. Looking at the VIPR sequences more, it looks like most of the human LASV sequences were split into GP1 and GP2 sequences in the database. As such, I will ignore the VIPR sequences and just use the GenBank sequences. \n",
    "\n",
    "As far as I can tell, all the VIPR sequences are also indexed in genbank, so this should still be most of the available mammarenavirus sequences. \n",
    "\n",
    "Note: I am starting with a mammarenavirus alignment. This includes New World and Old World mammarenaviruses, which use two different receptors (alpha-dystroglycan for Old World and transferin receptor for New World). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seqs_df\n",
    "\n",
    "Set `seqs_df` to be the collection of mammarenavirus sequences downloaded from genbank with the \"glycoprotein\" search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seqs_df = gb_mammarenavirus_glycoprotein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter sequences by length\n",
    "\n",
    "Based on the above histogram, it seems reasonable to include sequences >405 amino acids and <550 amino acids in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seqs_df = seqs_df[(seqs_df['Length'] < 550) & (seqs_df['Length'] > 405)]\n",
    "print(len(seqs_df))\n",
    "display(seqs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out sequences with > 10 `X`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seqs_df = seqs_df[(seqs_df['Seq'].str.count('X')<=10)]\n",
    "print(len(seqs_df))\n",
    "display(seqs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset on LASV Seqs for initial alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_seqs_df = seqs_df[(seqs_df['Description'].str.contains('Lassa'))]\n",
    "print(len(lasv_seqs_df))\n",
    "display(lasv_seqs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "jos_id = 'NP_694870.1'\n",
    "jos_seq_df = seqs_df[(seqs_df['Description'].str.contains(jos_id))]\n",
    "display(jos_seq_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "g1959_id = 'AIT17216.1'\n",
    "g1959_seq_df = seqs_df[(seqs_df['Description'].str.contains(g1959_id))]\n",
    "display(g1959_seq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output filtered sequences to `fasta` files for alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open('./gpcs_filtered.fasta', 'w') as outfile:\n",
    "    for idx in range(len(seqs_df)):\n",
    "        outfile.write(f\">{seqs_df.iloc[idx]['ID']}\\n\")\n",
    "        outfile.write(f\"{seqs_df.iloc[idx]['Seq']}\\n\")\n",
    "        \n",
    "with open('./lasv_gpcs.fasta', 'w') as outfile:\n",
    "    for idx in range(len(lasv_seqs_df)):\n",
    "        outfile.write(f\">{lasv_seqs_df.iloc[idx]['ID']}\\n\")\n",
    "        outfile.write(f\"{lasv_seqs_df.iloc[idx]['Seq']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `mafft` to align filtered GPC sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_align_outfile = './gpc_filtered_alignment.fasta'\n",
    "lasv_align_outfile = './lasv_alignment.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(gpc_align_outfile):\n",
    "    ! mafft --retree 2 --maxiterate 1000 --quiet 'gpcs_filtered.fasta' > './gpc_filtered_alignment.fasta'\n",
    "    print('Aligned GPC sequences with MAFFT (MAFFT output silenced).')\n",
    "else:\n",
    "    print('GPC alignment already exists. Using existing alignment.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(lasv_align_outfile):\n",
    "    ! mafft --retree 2 --maxiterate 1000 --quiet 'lasv_gpcs.fasta' > './lasv_alignment.fasta'\n",
    "    print('Aligned LASV sequences with MAFFT (MAFFT output silenced).')\n",
    "else:\n",
    "    print('LASV alignment already exists. Using existing alignment.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at LASV GP Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_align = AlignIO.read(lasv_align_outfile, \"fasta\")\n",
    "print(f\"{len(lasv_align)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract LASV Josiah GP sequence as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for seq in lasv_align:\n",
    "    if seq.description == jos_id:\n",
    "        jos_align = seq\n",
    "\n",
    "print(jos_align)\n",
    "print()\n",
    "print(jos_align.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create df of percent IDs for LASV GP seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_pids_df = pd.DataFrame()\n",
    "for seq in lasv_align:\n",
    "    lasv_pids_df = pd.concat([lasv_pids_df, percent_ids(jos_align.seq, seq.seq, seq.id)]).reset_index(drop=True)\n",
    "    \n",
    "display(lasv_pids_df.sort_values('pid_aa', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pids_plot = (ggplot(lasv_pids_df, aes(x='pid_aa')) +\n",
    "                    geom_histogram(binwidth=0.005) +\n",
    "                    theme(axis_text_x=element_text(angle=90, vjust=1, hjust=0.5)) +\n",
    "                    scale_x_continuous(limits=[0.88, 1.0], breaks=[0.88, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0])\n",
    "               )\n",
    "\n",
    "_ = pids_plot.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Phylogenetic Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_tree_outfile = './lasv.treefile'\n",
    "\n",
    "# use Pinneo strain as outgroup, as typically done.\n",
    "\n",
    "if not os.path.isfile(lasv_tree_outfile):\n",
    "    ! iqtree -s lasv_alignment.fasta -pre lasv -nt 4 -m LG+F+G -o 'AIT17836.1' -quiet\n",
    "else:\n",
    "    print('LASV tree already constructed. Using existing tree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_lineages = {'I: Pinneo': ['AIT17836.1'], 'II: Nigeria (S)': ['ADU56610.1', 'AAF86703.1'], 'III: Nigeria (C)': ['ADU56618.1', 'CAA36645.1'],\n",
    "                 'IV: Sierra Leone (Josiah)': [jos_id], 'IV: Sierra Leone': [g1959_id], 'IV: Liberia': ['AAT49008.1'], 'IV: Guinea': ['AAT49000.1'],\n",
    "                 'Guinea (mouse)': ['ADI39451.1'], 'SL (mouse)': ['AIT17840.1'], 'Nigeria': ['AIT17646.1', 'AIT17556.1', 'AIT17540.1'],\n",
    "                 'Nigeria (CSF)': ['AAL13212.1'], 'Benin (mouse)': ['QCF45564.1'],\n",
    "                 'V: Mali, Ivory Coast': ['AHC95553.1'], 'VI: Nigeria (Hylomyscus)': ['ANH09740.1'], 'VII: Togo': ['SCA79105.1']}\n",
    "\n",
    "lasv_tree_labels = [item for sublist in lasv_lineages.values() for item in sublist]\n",
    "print(lasv_tree_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_key(val, my_dict): \n",
    "    for key, value in my_dict.items():\n",
    "        if val in value: \n",
    "            return(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tree = Phylo.read(lasv_tree_outfile, \"newick\")\n",
    "# tree.root_at_midpoint()\n",
    "# tree.ladderize()  # Flip branches so deeper clades are displayed at top\n",
    "\n",
    "treedir = './'\n",
    "\n",
    "treefigfile = os.path.join(treedir, 'lasv_tree_plot.pdf')\n",
    "\n",
    "Phylo.draw(tree, label_func=lambda x: get_key(str(x), lasv_lineages) if str(x) in lasv_tree_labels else '', \n",
    "           label_colors=dict([(lineage, 'red') for lineage in lasv_lineages.keys()]),\n",
    "           do_show=False)\n",
    "\n",
    "\n",
    "treefig = plt.gcf()\n",
    "treefig.set_size_inches(7, 24)\n",
    "ax = treefig.axes[0]\n",
    "ax.axis('off')\n",
    "\n",
    "# add scale bar\n",
    "(x0, x1, y0, y1) = plt.axis()\n",
    "xstart = x0 + 0.3 * (x1 - x0)\n",
    "barlen = 0.1\n",
    "yline = y0 - 0.05 * (y1 - y0)\n",
    "ytext = yline - 0.01 * (y1 - y0)\n",
    "ax.set_ylim(ytext, y1)\n",
    "plt.plot([xstart, xstart + barlen], [yline, yline], color='black', \n",
    "        linestyle='-', linewidth=2)\n",
    "plt.text(xstart + barlen / 2., ytext, \n",
    "        '{0:.1} amino acid substitutions / site'.format(barlen),\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='top',\n",
    "        color='black',\n",
    "        fontsize=17)\n",
    "\n",
    "treefig.tight_layout()\n",
    "treefig.savefig(treefigfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find gaps in Josiah GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gaps = []\n",
    "for i in range(len(jos_align.seq)):\n",
    "    if jos_align.seq[i] == '-':\n",
    "        gaps.append(i)\n",
    "        \n",
    "print(gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop first 35 sites and last site of alignment so don't include gaps in Josiah alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lasv_align_nogaps=lasv_align[:, 35:526]\n",
    "jos_align_nogaps=jos_align[35:526]\n",
    "print(jos_align_nogaps.seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up code:\n",
    "\n",
    "## Make character counting and plotting code functions so can run on the different alignments more easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate counts for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_alignment(refseq, alignment, mincount=1):\n",
    "    site_char_counts = {}\n",
    "    for i in range(len(refseq.seq)):\n",
    "        char_counts = {}\n",
    "        for char in set(alignment[:, i]):\n",
    "            char_counts[char] = alignment[:, i].count(char)\n",
    "        site_char_counts[i] = char_counts\n",
    "    \n",
    "    site_char_counts_df = pd.DataFrame.from_dict(site_char_counts)\n",
    "        \n",
    "    # transpose df so site is index, then drop cells where count less than mincount\n",
    "    scc_transpose = site_char_counts_df.transpose()\n",
    "    \n",
    "    if mincount != 1:\n",
    "        scc_transpose = scc_transpose.where(scc_transpose >= mincount)\n",
    "    \n",
    "    # make site column with 1-indexing\n",
    "    scc_transpose['site'] = scc_transpose.index+1\n",
    "\n",
    "    # add in info on max counts for each aa at each site and num dif aa at each site\n",
    "    # first subset on df excluding gaps and xs\n",
    "    scc_nogaps_nox = scc_transpose.drop(['-', 'X', 'site'], axis=1)\n",
    "    # add 'max_nogap' column for max count for any given aa at site without counting gaps\n",
    "    scc_transpose['max_nogap'] = scc_nogaps_nox[scc_nogaps_nox.columns].max(axis=1)\n",
    "    # add 'num_dif_nogap' column for num of dif aas at each site not including xs or gaps\n",
    "    scc_transpose['num_dif_nogap'] = (scc_nogaps_nox.count(axis=1)-1) # only count \"extra\" aas, not first\n",
    "    # fill na\n",
    "    scc_transpose = scc_transpose.fillna(0)\n",
    "    \n",
    "    display(scc_transpose.head())\n",
    "    \n",
    "    return scc_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasv_align_df = process_alignment(jos_align_nogaps, lasv_align_nogaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plots:\n",
    "\n",
    "1. Max count for any one amino acid at each site\n",
    "2. Number gaps at each site\n",
    "3. Number different amino acids at each site\n",
    "\n",
    "In all plots, the rough separations are colored as below:\n",
    "* SSP/GP1: blue dashed line\n",
    "* GP1/GP2: green dashed line\n",
    "* GP2/TM: orange dashed line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def make_line_plots(align_df, subset_name):\n",
    "    max_count_plot = (ggplot(align_df, aes(x='site', y='max_nogap')) +\n",
    "                         geom_line() +\n",
    "                         geom_vline(xintercept=59.5, linetype='dashed', color='blue') +\n",
    "                         geom_vline(xintercept=259.5, linetype='dashed', color='green') +\n",
    "                         geom_vline(xintercept=427.5, linetype='dashed', color='orange') +\n",
    "                        ggtitle(f\"{subset_name}: max_count_plot\")\n",
    "                 )\n",
    "\n",
    "    _ = max_count_plot.draw()\n",
    "    \n",
    "    num_gap_plot = (ggplot(align_df, aes(x='site', y='-')) +\n",
    "                       geom_line() +\n",
    "                       geom_vline(xintercept=59.5, linetype='dashed', color='blue') +\n",
    "                       geom_vline(xintercept=259.5, linetype='dashed', color='green') +\n",
    "                       geom_vline(xintercept=427.5, linetype='dashed', color='orange') +\n",
    "                       ggtitle(f\"{subset_name}: num_gap_plot\")\n",
    "               )\n",
    "\n",
    "    _ = num_gap_plot.draw()\n",
    "    \n",
    "    num_dif_plot = (ggplot(align_df, aes(x='site', y='num_dif_nogap')) +\n",
    "                       geom_line() +\n",
    "                       geom_vline(xintercept=59.5, linetype='dashed', color='blue') +\n",
    "                       geom_vline(xintercept=259.5, linetype='dashed', color='green') +\n",
    "                       geom_vline(xintercept=427.5, linetype='dashed', color='orange') +\n",
    "#                        scale_y_continuous(breaks=range(0, 12, 1)) +\n",
    "                       ggtitle(f\"{subset_name}: num_dif_plot\")\n",
    "               )\n",
    "\n",
    "    _ = num_dif_plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_line_plots(lasv_align_df, 'LASV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(lasv_align[50:100, 85:105]) # indices of full alignment shifted 35 from Jos alignment due to initial gap\n",
    "print(jos_align.seq[85:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, a lot of sequences have a gap at site 60 (note, with \"auto\" alignment this gap was at site 59 or 60). \n",
    "\n",
    "Looking at [this paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7232328/), having a residue at site 60 seems to be unique to Lineage IV viruses (such as Josiah and G1959 strains). Note also that my plotting indexing is 1-indexing, but the alignment indexing is 0-indexed.\n",
    "\n",
    "Note the SSP/GP1 cleavage site is between the two `T`s at sites 57/58. \n",
    "\n",
    "Looking at a few of the alignments (above) it seems like this gap is real, not some sequence alignment artifact. I should dig into if LASV GPs from different lineages are known to either have or not have this gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conserved_sites = lasv_align_df[lasv_align_df['num_dif_nogap']==0]['site']\n",
    "conserved_sites_ectodomain = [x for x in conserved_sites if x <427]\n",
    "print(conserved_sites_ectodomain)\n",
    "print('\\nNumber of conserved sites:')\n",
    "print(len(conserved_sites_ectodomain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above analysis, there are 260 sites with no variability in the LASV GP alignment.\n",
    "\n",
    "Not mutating those sites would just about halve the library size.\n",
    "\n",
    "I will next look at the full mammarenavirus alignment to see if therer are sites with diversity in the full alignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at full mammarenavirus GPC alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_align = AlignIO.read(\"gpc_filtered_alignment.fasta\", \"fasta\")\n",
    "print(f\"{len(gpc_align)} sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Josiah sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for seq in gpc_align:\n",
    "    if seq.description == jos_id:\n",
    "        jos_full_align = seq\n",
    "\n",
    "print(jos_full_align)\n",
    "print()\n",
    "print(jos_full_align.seq)\n",
    "\n",
    "print(len(jos_full_align.seq))\n",
    "print(jos_full_align.seq.count('-'))\n",
    "print(len(jos_full_align.seq) - jos_full_align.seq.count('-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at percent ids in full alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_pids_df = pd.DataFrame()\n",
    "for seq in gpc_align:\n",
    "    all_pids_df = pd.concat([all_pids_df, percent_ids(jos_full_align.seq, seq.seq, seq.id)]).reset_index(drop=True)\n",
    "    \n",
    "display(all_pids_df.sort_values('pid_aa', ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_pids_plot = (ggplot(all_pids_df, aes(x='pid_aa')) +\n",
    "                    geom_histogram(binwidth=0.005) +\n",
    "                    theme(axis_text_x=element_text(angle=90, vjust=1, hjust=0.5)) +\n",
    "                    scale_x_continuous(limits=[0.4, 1.0], breaks=[0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1])\n",
    "               )\n",
    "\n",
    "_ = all_pids_plot.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "low_pid_df = all_pids_df[(all_pids_df['pid_aa'] < 0.55)].sort_values('pid_aa')\n",
    "display(low_pid_df.head())\n",
    "low_pid_ids = low_pid_df['seq_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on GenBank searches of IDs with percent amino acid identities <55%, the group of GPs with the least identity to LASV GP Josiah seem to all be New World mammarenaviruses. This makes sense as most of those use a different receptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(all_pids_df[(all_pids_df['pid_aa'] >= 0.55) & (all_pids_df['pid_aa'] < 0.7)].sort_values('pid_aa').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cluster of around 60% identity is Old World mammarenavirus, mostly LCMV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(all_pids_df[(all_pids_df['pid_aa'] >= 0.7) & (all_pids_df['pid_aa'] < 0.756)].sort_values('pid_aa').head())\n",
    "display(all_pids_df[(all_pids_df['pid_aa'] >= 0.7) & (all_pids_df['pid_aa'] < 0.756)].sort_values('pid_aa').tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 0.7 - 0.75 percent aa identity, are Old World mammarenaviruses, including many (mostly) from SE Asia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "display(all_pids_df[(all_pids_df['pid_aa'] >= 0.756) & (all_pids_df['pid_aa'] < 0.8)].sort_values('pid_aa').head())\n",
    "display(all_pids_df[(all_pids_df['pid_aa'] >= 0.756) & (all_pids_df['pid_aa'] < 0.8)].sort_values('pid_aa').tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 0.75-0.8 percent aa identity are more Old World arenaviruses mainly (mostly) in Africa, largely of infecting the same/similar rodents as LASV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tree from full alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_tree_outfile = './gpc_all.treefile'\n",
    "\n",
    "if not os.path.isfile(gpc_tree_outfile):\n",
    "    ! iqtree -s gpc_filtered_alignment.fasta -pre gpc_all -nt AUTO -m LG+F+G -quiet\n",
    "else:\n",
    "    print('GPC tree already constructed. Using existing tree.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_labels = {'LASV I': ['AIT17836.1'], 'LASV II': ['ADU56610.1', 'AAF86703.1'], 'LASV III': ['ADU56618.1', 'CAA36645.1'],\n",
    "              'LASV IV': [jos_id, g1959_id, 'AAT49008.1', 'AAT49000.1'],\n",
    "              'LASV Guinea (mouse)': ['ADI39451.1'], 'LASV SL (mouse)': ['AIT17840.1'], 'LASV Nigeria (CSF)': ['AAL13212.1'],\n",
    "              'LASV V': ['AHC95553.1'], 'LASV VI': ['ANH09740.1'], 'LASV VII': ['SCA79105.1'], \n",
    "              'LCMV': ['AAA46256.1', 'AAA46265.1'], 'Ippy': ['YP_516230.1'], 'Oliveros': ['AAC54654.1'], 'Pichinde': ['AAA46824.1'],\n",
    "              'Junin': ['AAU34180.1'], 'Tacaribe': ['NP_694849.1'], 'Machupo': ['NP_899212.1'],\n",
    "              'Mopeia': ['AAC08700.1', 'ABC71134.1'], 'Mobala': ['YP_516226.1'], 'Guanarito': ['NP_899210.1'], \n",
    "              'Catarina': ['ABI97298.1'], 'Bear Canyon': ['AAN32965.1'], 'Flexal': ['AAN32961.1'],\n",
    "              'Lujo': ['YP_002929490.1'], 'Latino': ['AAN32959.1'], 'Wenzhou': ['YP_009113206.1'], 'Luna': ['BAU22158.1']}\n",
    "\n",
    "gpc_colors = {'LASV I': 'red', 'LASV II': 'red', 'LASV III': 'red', 'LASV IV': 'red', 'LASV Guinea (mouse)': 'red',\n",
    "              'LASV SL (mouse)': 'red', 'LASV Nigeria (CSF)': 'red', 'LASV V': 'red', 'LASV VI': 'red', 'LASV VII': 'red', \n",
    "              'LCMV': 'orange', 'Ippy': 'orange', 'Oliveros': 'blue', 'Pichinde': 'blue',\n",
    "              'Junin': 'blue', 'Tacaribe': 'blue', 'Machupo': 'blue', 'Lujo': 'orange',\n",
    "              'Mopeia': 'orange', 'Mobala': 'orange', 'Guanarito': 'blue', 'Catarina': 'blue',\n",
    "              'Bear Canyon': 'blue', 'Flexal': 'blue', 'Latino': 'blue', 'Wenzhou': 'orange', 'Luna': 'orange'}\n",
    "\n",
    "gpc_tree_labels = [item for sublist in gpc_labels.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display pids for labeled viruses and LASV\n",
    "for virus in gpc_labels:\n",
    "    print(virus)\n",
    "    seqid_list = gpc_labels[virus]\n",
    "    display(all_pids_df[(all_pids_df['seq_id'].isin(seqid_list))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tree = Phylo.read(gpc_tree_outfile, \"newick\")\n",
    "tree.root_at_midpoint()\n",
    "tree.ladderize()  # Flip branches so deeper clades are displayed at top\n",
    "\n",
    "treedir = './'\n",
    "\n",
    "treefigfile = os.path.join(treedir, 'gpc_tree_plot.pdf')\n",
    "\n",
    "Phylo.draw(tree, label_func=lambda x: get_key(str(x), gpc_labels) if str(x) in gpc_tree_labels else '', \n",
    "           label_colors=gpc_colors,\n",
    "           do_show=False)\n",
    "\n",
    "\n",
    "treefig = plt.gcf()\n",
    "treefig.set_size_inches(7, 30)\n",
    "ax = treefig.axes[0]\n",
    "ax.axis('off')\n",
    "\n",
    "# add scale bar\n",
    "(x0, x1, y0, y1) = plt.axis()\n",
    "xstart = x0 + 0.3 * (x1 - x0)\n",
    "barlen = 0.1\n",
    "yline = y0 - 0.05 * (y1 - y0)\n",
    "ytext = yline - 0.01 * (y1 - y0)\n",
    "ax.set_ylim(ytext, y1)\n",
    "plt.plot([xstart, xstart + barlen], [yline, yline], color='black', \n",
    "        linestyle='-', linewidth=2)\n",
    "plt.text(xstart + barlen / 2., ytext, \n",
    "        '{0:.1} amino acid substitutions / site'.format(barlen),\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='top',\n",
    "        color='black',\n",
    "        fontsize=17)\n",
    "\n",
    "treefig.tight_layout()\n",
    "treefig.savefig(treefigfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create alignments that are just Old or New World Arenaviruses\n",
    "\n",
    "Made these alignments, but decided to continue doing analyses with full alignment becuase: \n",
    "\n",
    "1. I will just use degenerate nucleotides for GP1 anyway\n",
    "2. I only want to exclude _really_ conserved sites in GP2\n",
    "\n",
    "Although, really I should probably do these analyses for both with and without the New World sequences included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_align_ow = MultipleSeqAlignment([])\n",
    "gpc_align_nw = MultipleSeqAlignment([])\n",
    "\n",
    "for i in range(len(gpc_align)):\n",
    "    if gpc_align[i].id in low_pid_ids.to_list():\n",
    "        gpc_align_nw.append(gpc_align[i])\n",
    "    else:\n",
    "        gpc_align_ow.append(gpc_align[i])\n",
    "\n",
    "assert len(low_pid_ids.to_list()) == len(gpc_align_nw)\n",
    "assert len(gpc_align_ow) + len(gpc_align_nw) == len(gpc_align)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all sites from alignment that introduce a gap in LASV Josiah GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "keep_starts = []\n",
    "keep_ends = []\n",
    "drop_zero = False\n",
    "\n",
    "drop_sites = []\n",
    "\n",
    "for i in range(len(jos_full_align.seq)):\n",
    "    if i != 0:\n",
    "        if (jos_full_align[i] == '-') and (jos_full_align[i-1] != '-'):\n",
    "            keep_ends.append(i)\n",
    "        elif (jos_full_align[i] != '-') and (jos_full_align[i-1] == '-'):\n",
    "            keep_starts.append(i)\n",
    "    else:\n",
    "        if jos_full_align[i] == '-':\n",
    "            drop_zero = True\n",
    "        else:\n",
    "            keep_starts.append(i)\n",
    "    \n",
    "    if jos_full_align[i] == '-':\n",
    "        drop_sites.append(i)\n",
    "            \n",
    "\n",
    "print(keep_starts)\n",
    "print(keep_ends)\n",
    "print(drop_zero)\n",
    "# print()\n",
    "# print(drop_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The below analyses are for all 3 GPC_all alignments (OW, NW, and all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gpc_align_ow_nogaps = gpc_align_ow[:, keep_starts[0]:keep_ends[0]]\n",
    "gpc_align_nw_nogaps = gpc_align_nw[:, keep_starts[0]:keep_ends[0]]\n",
    "gpc_align_all_nogaps = gpc_align[:, keep_starts[0]:keep_ends[0]]\n",
    "for i in range(1, len(keep_starts)):\n",
    "    gpc_align_ow_nogaps += gpc_align_ow[:, keep_starts[i]:keep_ends[i]]\n",
    "    gpc_align_nw_nogaps += gpc_align_nw[:, keep_starts[i]:keep_ends[i]]\n",
    "    gpc_align_all_nogaps += gpc_align[:, keep_starts[i]:keep_ends[i]]\n",
    "\n",
    "print('OldWorld')\n",
    "print(gpc_align_ow_nogaps)\n",
    "print('\\nNewWorld')\n",
    "print(gpc_align_nw_nogaps)\n",
    "print('\\nAll')\n",
    "print(gpc_align_all_nogaps)\n",
    "print()\n",
    "\n",
    "for seq in gpc_align_all_nogaps:\n",
    "    if seq.description == jos_id:\n",
    "        jos_full_align_nogaps = seq\n",
    "\n",
    "print(jos_full_align_nogaps)\n",
    "print()\n",
    "print(jos_full_align_nogaps.seq)\n",
    "print(len(jos_full_align_nogaps.seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OldWorld\\n')\n",
    "ow_align_df = process_alignment(jos_full_align_nogaps, gpc_align_ow_nogaps)\n",
    "print('\\nNewWorld\\n')\n",
    "nw_align_df = process_alignment(jos_full_align_nogaps, gpc_align_nw_nogaps)\n",
    "print('\\nAll\\n')\n",
    "all_align_df = process_alignment(jos_full_align_nogaps, gpc_align_all_nogaps)\n",
    "all_align_df_min2 = process_alignment(jos_full_align_nogaps, gpc_align_all_nogaps, mincount=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of mutations included in alignment\n",
    "\n",
    "Add up `num_dif_nogap` plus the length of the alignment to determine single mutants in alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# exclude TM and cytoplasmic domains\n",
    "align_df_dict = {'OldWorld': ow_align_df, 'NewWorld': nw_align_df, 'All': all_align_df, 'All_Min2': all_align_df_min2}\n",
    "for subset in align_df_dict:\n",
    "    print(f\"\\n{subset}\")\n",
    "    gp1_2 = align_df_dict[subset].iloc[:427]\n",
    "    print('Muts in alignment excluding TM+C-tail:')\n",
    "    print(gp1_2['num_dif_nogap'].sum() + len(gp1_2))\n",
    "\n",
    "print('\\nTotal muts in GPC (excluding TM+C-tail)')\n",
    "print(427*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make heatmap of amino acid counts at each site for full alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scc_heatmap = all_align_df.drop(['site', 'max_nogap', 'num_dif_nogap'], axis=1).transpose().replace(0, np.nan)\n",
    "scc_hm_melt = scc_heatmap.melt(ignore_index=False).reset_index().rename(columns={'index': 'aa', 'variable': 'site', 'value': 'count'})\n",
    "\n",
    "aa_order = ['R', 'K', 'H', 'D', 'E', 'Q', 'N', 'S', 'T',\n",
    "            'Y', 'W', 'F', 'A', 'I', 'L', 'M', 'V', 'G', 'P', 'C', '-', 'X']\n",
    "scc_hm_melt.aa = scc_hm_melt.aa.astype(\"category\")\n",
    "scc_hm_melt.aa.cat.set_categories(aa_order, inplace=True)\n",
    "\n",
    "scc_hm_melt = scc_hm_melt.sort_values(['aa', 'site'])\n",
    "\n",
    "display(scc_hm_melt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "heatmap = alt.Chart(scc_hm_melt).mark_rect().encode(\n",
    "                    alt.X('site:O'),\n",
    "                    alt.Y(\"aa:O\", sort=alt.EncodingSortField(field='order', order='ascending')),\n",
    "                    color=alt.Color('count:Q', scale=alt.Scale(scheme=\"Blues\")),\n",
    "                    tooltip=[\n",
    "                        alt.Tooltip('aa:O', title='Amino Acid'),\n",
    "                        alt.Tooltip('site:O', title='Site'),\n",
    "                        alt.Tooltip('count:Q', title='Count')\n",
    "                        ]\n",
    "                    ).properties(width=5000)\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Drop amino acids with < 5 counts from heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "scc_hm_melt_2 = scc_hm_melt.copy()\n",
    "scc_hm_melt_2['count'] = scc_hm_melt_2['count'].replace([1, 2, 3, 4, 5], np.nan)\n",
    "# scc_hm_melt_2['count'] = scc_hm_melt_2['count'].replace(2, np.nan)\n",
    "\n",
    "heatmap = alt.Chart(scc_hm_melt_2).mark_rect().encode(\n",
    "                    alt.X('site:O'),\n",
    "                    alt.Y(\"aa:O\", sort=alt.EncodingSortField(field='order', order='ascending')),\n",
    "                    color=alt.Color('count:Q', scale=alt.Scale(scheme=\"Blues\")),\n",
    "                    tooltip=[\n",
    "                        alt.Tooltip('aa:O', title='Amino Acid'),\n",
    "                        alt.Tooltip('site:O', title='Site'),\n",
    "                        alt.Tooltip('count:Q', title='Count')\n",
    "                        ]\n",
    "                    ).properties(width=5000)\n",
    "\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make line plots:\n",
    "\n",
    "1. Max count for any one amino acid at each site\n",
    "2. Number gaps at each site\n",
    "3. Number different amino acids at each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for subset in align_df_dict:\n",
    "    make_line_plots(align_df_dict[subset], subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(gpc_align[:, 85:105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count sites that are conserved across each full GPC alignment in all sites upstream of TM+C-tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for subset in align_df_dict:\n",
    "    align_df = align_df_dict[subset]\n",
    "    conserved_sites_subset = align_df[align_df['num_dif_nogap']==0].site\n",
    "    conserved_sites_subset_list = []\n",
    "    for site in conserved_sites_subset:\n",
    "        if site <= 427:\n",
    "            conserved_sites_subset_list.append(site)\n",
    "    print(f\"\\n{subset}:\")\n",
    "    print(conserved_sites_subset_list)\n",
    "    print(f\"{len(conserved_sites_subset_list)} conserved sites in the ectodomain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "After discussing above results with Jesse and Tyler, I don't feel like we have sufficient information to necessarily want to limit our library based only on currently available sequences. \n",
    "\n",
    "Furthermore, titers of LASV Josiah pseudotyped-lentiviruses recovered from transduced cells are now very high (on the order of 1e5 TU/mL), meaning it is not as necessary to limit library size as it would have been with lower titers. \n",
    "\n",
    "Additionally, papers from non-human primate challenge studies have identified potential escape mutations in LASV GP Josiah following treatment with some of the antibodies I will test. \n",
    "\n",
    "Therefore, I will simply order NNS primers that span LASV GP Josiah. I will likely include the signal peptide in the library since the signal peptide is a part of the final GPC complex. However, I will likely exclude the transmembrane domain and cytoplasmic tail as mutations there are likely negative or neutral. Indeed, looking at the analyses above, the TM domain (immediately following site 427) is fairly conserved. There is more variability in the cytoplasmic tail, but that is likely not playing a large role in function/evolution/antigenicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
